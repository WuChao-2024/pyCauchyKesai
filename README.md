# pyCauchyKesai
RDK Tools



ä»¥ä¸‹æ˜¯æ ¹æ®ä½ æä¾›çš„ C++ ç±» `CauchyKesai` å’Œå…¶ pybind11 æ¥å£ç”Ÿæˆçš„ **è‹±æ–‡ç‰ˆæ¥å£æ–‡æ¡£ï¼ˆAPI Documentationï¼‰**ï¼Œé€‚ç”¨äºæŠ€æœ¯æ–‡æ¡£ã€SDK è¯´æ˜æˆ–å¼€å‘è€…æ‰‹å†Œã€‚

---

# ğŸ“˜ `CauchyKesai` API Reference (English)

The `CauchyKesai` class is a C++ implementation for loading and running BPU models, exposed to Python via `pybind11`. It supports multi-task inference, asynchronous execution, performance profiling, and safe model interaction.

---

## ğŸ”§ Constructor

```python
CauchyKesai(model_path: str, n_task: int = 1, model_cnt_select: int = 0)
```

### Parameters:

| Parameter | Type | Default | Description |
|----------|------|---------|-------------|
| `model_path` | `str` | â€” | Path to the BPU model file (e.g., `.hbmodel`) |
| `n_task` | `int` | `1` | Number of concurrent tasks allowed |
| `model_cnt_select` | `int` | `0` | Model index selector (used in multi-model scenarios) |

---

## ğŸ“š Public Methods

### 1. `.summ()`
- **Description**: Prints a summary of the model's input/output tensor properties.
- **Returns**: None
- **Example**:
  ```python
  model.summ()
  ```

---

### 2. `.t()`
- **Description**: Runs one dirty inference pass and prints performance metrics (e.g., latency, throughput).
- **Returns**: None
- **Example**:
  ```python
  model.t()
  ```

---

### 3. `.start(inputs: List[np.ndarray], task_id: int = 0, priority: int = 0)`
- **Description**: Starts an asynchronous inference task.
- **Parameters**:
  | Parameter | Type | Default | Description |
  |----------|------|---------|-------------|
  | `inputs` | `List[np.ndarray]` | â€” | List of input tensors as NumPy arrays |
  | `task_id` | `int` | `0` | Task ID for identifying this inference request |
  | `priority` | `int` | `0` | Priority level (higher value means higher priority) |
- **Returns**: None (use `.wait()` to retrieve results)

---

### 4. `.wait(task_id: int = 0) -> List[np.ndarray]`
- **Description**: Waits for the specified task to complete and returns output tensors with zero-copy optimization.
- **Parameters**:
  | Parameter | Type | Default | Description |
  |----------|------|---------|-------------|
  | `task_id` | `int` | `0` | The task ID to wait for |
- **Returns**: `List[np.ndarray]` - Output tensors as NumPy arrays

---

### 5. `.inference(inputs: List[np.ndarray], task_id: int = 0, priority: int = 0) -> List[np.ndarray]`
- **Description**: Safe call that performs: check + start + wait. Suitable for one-time inference.
- **Parameters**:
  | Parameter | Type | Default | Description |
  |----------|------|---------|-------------|
  | `inputs` | `List[np.ndarray]` | â€” | Input tensors |
  | `task_id` | `int` | `0` | Task ID |
  | `priority` | `int` | `0` | Task priority |
- **Returns**: `List[np.ndarray]` - Output tensors

---

### 6. `__call__(inputs: List[np.ndarray], task_id: int = 0, priority: int = 0) -> List[np.ndarray]`
- **Description**: Callable interface, equivalent to `.inference(...)`.
- **Example**:
  ```python
  outputs = model([input1, input2])
  ```

---

## ğŸ§  Internal Member Variables (for reference only)

| Variable Name | Type | Description |
|---------------|------|-------------|
| `model_path_` | `std::string` | Model path string |
| `n_task_` | `int32_t` | Max number of concurrent tasks |
| `is_infer` | `std::vector<int>` | Inference status per task |
| `task_handles` | `std::vector<hbUCPTaskHandle_t>` | Task handle list |
| `packed_dnn_handle`, `dnn_handle` | `hbDNN*` | DNN runtime handles |
| `input_properties`, `output_properties` | `hbDNNTensorProperties` | Tensor metadata |
| `inputs_shape`, `outputs_shape` | `std::vector<std::vector<size_t>>` | Input/output shapes |
| `inputs_dtype`, `outputs_dtype` | `std::vector<std::string>` | Data types (e.g., float32, uint8) |

---

## ğŸ§ª Example Usage (Python)

```python
import cauchy_kesai as ck
import numpy as np

# Load model
model = ck.CauchyKesai("/path/to/model", n_task=2)

# Print model summary
model.summ()

# Prepare inputs
input_data = [np.random.rand(1, 3, 224, 224).astype(np.float32)]

# Run inference
output = model(input_data)

# Async usage
model.start(input_data, task_id=0)
result = model.wait(task_id=0)
```

---

## âœ… Summary of Recommended Usage

| Method | Recommendation | Use Case |
|--------|----------------|----------|
| `.inference()` / `__call__()` | âœ… Recommended | One-time safe inference |
| `.start()` + `.wait()` | âœ… Recommended | Asynchronous control |
| `.summ()` | âœ… Recommended | View model structure |
| `.t()` | âš ï¸ For testing | Quick performance test |

---

å¦‚æœä½ éœ€è¦å°†è¿™ä»½æ–‡æ¡£å¯¼å‡ºä¸º Markdown æ–‡ä»¶ã€HTML é¡µé¢æˆ–é›†æˆåˆ° Sphinx æ–‡æ¡£ç³»ç»Ÿä¸­ï¼Œæˆ‘ä¹Ÿå¯ä»¥å¸®ä½ ä¸€é”®ç”Ÿæˆ ğŸ˜Š